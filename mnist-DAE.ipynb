{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root='../data', train=True, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "def plot_sample_img(img, name):\n",
    "    img = img.view(1, 28, 28)\n",
    "    save_image(img, './sample_{}.png'.format(name))\n",
    "\n",
    "\n",
    "def min_max_normalization(tensor, min_value, max_value):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor / max_tensor\n",
    "    tensor = tensor * (max_value - min_value) + min_value\n",
    "    return tensor\n",
    "\n",
    "def tensor_round(tensor):\n",
    "    return torch.round(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda tensor:min_max_normalization(tensor, 0, 1)),\n",
    "    transforms.Lambda(lambda tensor:tensor_round(tensor))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST('../data', transform=img_transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(True))\n",
    "        \n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 28*28),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.Encoder(x)\n",
    "            x = self.Decoder(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-ba3eaf37f626>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mMSE_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorcho\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorcho\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img)\n",
    "        \n",
    "        # forward\n",
    "        output = model(img)        \n",
    "        loss = criterion(output, img)\n",
    "        MSE_loss = nn.MSELoss()(output, img)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # log\n",
    "        print('epoch [{}/{}], loss:{:.4f}, MSE_loss:{:.4f}'\n",
    "            .format(epoch + 1, num_epochs, loss.data[0], MSE_loss.data[0]))\n",
    "        if epoch % 10 == 0:\n",
    "            x = to_img(img.cpu().data)\n",
    "            x_hat = to_img(output.cpu().data)\n",
    "            save_image(x, './mlp_img/x_{}.png'.format(epoch))\n",
    "            save_image(x_hat, './mlp_img/x_hat_{}.png'.format(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/200], loss: 0.10835842043161392\n",
      "epoch [2/200], loss: 0.07667386531829834\n",
      "epoch [3/200], loss: 0.06962911039590836\n",
      "epoch [4/200], loss: 0.06037367507815361\n",
      "epoch [5/200], loss: 0.05657651647925377\n",
      "epoch [6/200], loss: 0.051107924431562424\n",
      "epoch [7/200], loss: 0.05318485200405121\n",
      "epoch [8/200], loss: 0.05057459697127342\n",
      "epoch [9/200], loss: 0.0432075634598732\n",
      "epoch [10/200], loss: 0.04587759077548981\n",
      "epoch [11/200], loss: 0.043028824031353\n",
      "epoch [12/200], loss: 0.03823643922805786\n",
      "epoch [13/200], loss: 0.0371742881834507\n",
      "epoch [14/200], loss: 0.039610810577869415\n",
      "epoch [15/200], loss: 0.037864647805690765\n",
      "epoch [16/200], loss: 0.03420212119817734\n",
      "epoch [17/200], loss: 0.033305563032627106\n",
      "epoch [18/200], loss: 0.03279121592640877\n",
      "epoch [19/200], loss: 0.033255722373723984\n",
      "epoch [20/200], loss: 0.03365696594119072\n",
      "epoch [21/200], loss: 0.03221025690436363\n",
      "epoch [22/200], loss: 0.030603129416704178\n",
      "epoch [23/200], loss: 0.035512421280145645\n",
      "epoch [24/200], loss: 0.03428294137120247\n",
      "epoch [25/200], loss: 0.032179515808820724\n",
      "epoch [26/200], loss: 0.03158816695213318\n",
      "epoch [27/200], loss: 0.03349863365292549\n",
      "epoch [28/200], loss: 0.027852343395352364\n",
      "epoch [29/200], loss: 0.03275300934910774\n",
      "epoch [30/200], loss: 0.029935767874121666\n",
      "epoch [31/200], loss: 0.03010576032102108\n",
      "epoch [32/200], loss: 0.029318792745471\n",
      "epoch [33/200], loss: 0.02690347284078598\n",
      "epoch [34/200], loss: 0.028893720358610153\n",
      "epoch [35/200], loss: 0.03025362454354763\n",
      "epoch [36/200], loss: 0.030705779790878296\n",
      "epoch [37/200], loss: 0.03133827820420265\n",
      "epoch [38/200], loss: 0.027433142066001892\n",
      "epoch [39/200], loss: 0.028788134455680847\n",
      "epoch [40/200], loss: 0.029039163142442703\n",
      "epoch [41/200], loss: 0.027724292129278183\n",
      "epoch [42/200], loss: 0.02627081423997879\n",
      "epoch [43/200], loss: 0.027685480192303658\n",
      "epoch [44/200], loss: 0.028722479939460754\n",
      "epoch [45/200], loss: 0.023427216336131096\n",
      "epoch [46/200], loss: 0.026830678805708885\n",
      "epoch [47/200], loss: 0.02541954815387726\n",
      "epoch [48/200], loss: 0.025773320347070694\n",
      "epoch [49/200], loss: 0.025439729914069176\n",
      "epoch [50/200], loss: 0.029814917594194412\n",
      "epoch [51/200], loss: 0.029200706630945206\n",
      "epoch [52/200], loss: 0.024273032322525978\n",
      "epoch [53/200], loss: 0.024932151660323143\n",
      "epoch [54/200], loss: 0.02722223848104477\n",
      "epoch [55/200], loss: 0.024670090526342392\n",
      "epoch [56/200], loss: 0.02604733780026436\n",
      "epoch [57/200], loss: 0.027155982330441475\n",
      "epoch [58/200], loss: 0.02651861123740673\n",
      "epoch [59/200], loss: 0.02678750269114971\n",
      "epoch [60/200], loss: 0.024429280310869217\n",
      "epoch [61/200], loss: 0.026693403720855713\n",
      "epoch [62/200], loss: 0.027135882526636124\n",
      "epoch [63/200], loss: 0.027521967887878418\n",
      "epoch [64/200], loss: 0.026411009952425957\n",
      "epoch [65/200], loss: 0.024547921493649483\n",
      "epoch [66/200], loss: 0.026851847767829895\n",
      "epoch [67/200], loss: 0.0250608678907156\n",
      "epoch [68/200], loss: 0.022963417693972588\n",
      "epoch [69/200], loss: 0.027369678020477295\n",
      "epoch [70/200], loss: 0.025626255199313164\n",
      "epoch [71/200], loss: 0.02417222410440445\n",
      "epoch [72/200], loss: 0.0248011015355587\n",
      "epoch [73/200], loss: 0.027653483673930168\n",
      "epoch [74/200], loss: 0.022412922233343124\n",
      "epoch [75/200], loss: 0.02468312717974186\n",
      "epoch [76/200], loss: 0.025185052305459976\n",
      "epoch [77/200], loss: 0.02333049476146698\n",
      "epoch [78/200], loss: 0.026270678266882896\n",
      "epoch [79/200], loss: 0.023891594260931015\n",
      "epoch [80/200], loss: 0.024396585300564766\n",
      "epoch [81/200], loss: 0.022037362679839134\n",
      "epoch [82/200], loss: 0.024910179898142815\n",
      "epoch [83/200], loss: 0.02279561758041382\n",
      "epoch [84/200], loss: 0.023930871859192848\n",
      "epoch [85/200], loss: 0.025854764506220818\n",
      "epoch [86/200], loss: 0.025166045874357224\n",
      "epoch [87/200], loss: 0.024207189679145813\n",
      "epoch [88/200], loss: 0.02482452802360058\n",
      "epoch [89/200], loss: 0.02335507795214653\n",
      "epoch [90/200], loss: 0.024686498567461967\n",
      "epoch [91/200], loss: 0.024534771218895912\n",
      "epoch [92/200], loss: 0.023061014711856842\n",
      "epoch [93/200], loss: 0.023487048223614693\n",
      "epoch [94/200], loss: 0.023285502567887306\n",
      "epoch [95/200], loss: 0.0254781786352396\n",
      "epoch [96/200], loss: 0.02187543548643589\n",
      "epoch [97/200], loss: 0.025108514353632927\n",
      "epoch [98/200], loss: 0.02387860044836998\n",
      "epoch [99/200], loss: 0.021397503092885017\n",
      "epoch [100/200], loss: 0.02556763030588627\n",
      "epoch [101/200], loss: 0.024351881816983223\n",
      "epoch [102/200], loss: 0.023439642041921616\n",
      "epoch [103/200], loss: 0.024828528985381126\n",
      "epoch [104/200], loss: 0.02492666430771351\n",
      "epoch [105/200], loss: 0.021209856495261192\n",
      "epoch [106/200], loss: 0.022266002371907234\n",
      "epoch [107/200], loss: 0.022987984120845795\n",
      "epoch [108/200], loss: 0.023952528834342957\n",
      "epoch [109/200], loss: 0.024911776185035706\n",
      "epoch [110/200], loss: 0.024628771468997\n",
      "epoch [111/200], loss: 0.02372782677412033\n",
      "epoch [112/200], loss: 0.022730205208063126\n",
      "epoch [113/200], loss: 0.021872421726584435\n",
      "epoch [114/200], loss: 0.023073188960552216\n",
      "epoch [115/200], loss: 0.024118734523653984\n",
      "epoch [116/200], loss: 0.026415618136525154\n",
      "epoch [117/200], loss: 0.022571533918380737\n",
      "epoch [118/200], loss: 0.024223648011684418\n",
      "epoch [119/200], loss: 0.0284875500947237\n",
      "epoch [120/200], loss: 0.022053854539990425\n",
      "epoch [121/200], loss: 0.02438824065029621\n",
      "epoch [122/200], loss: 0.026389483362436295\n",
      "epoch [123/200], loss: 0.023780427873134613\n",
      "epoch [124/200], loss: 0.02261991985142231\n",
      "epoch [125/200], loss: 0.02369065396487713\n",
      "epoch [126/200], loss: 0.024057354778051376\n",
      "epoch [127/200], loss: 0.02275756560266018\n",
      "epoch [128/200], loss: 0.025690365582704544\n",
      "epoch [129/200], loss: 0.02296271175146103\n",
      "epoch [130/200], loss: 0.021610727533698082\n",
      "epoch [131/200], loss: 0.02473193034529686\n",
      "epoch [132/200], loss: 0.026545677334070206\n",
      "epoch [133/200], loss: 0.022772053256630898\n",
      "epoch [134/200], loss: 0.023688307031989098\n",
      "epoch [135/200], loss: 0.02539178356528282\n",
      "epoch [136/200], loss: 0.02530013397336006\n",
      "epoch [137/200], loss: 0.021273480728268623\n",
      "epoch [138/200], loss: 0.020800497382879257\n",
      "epoch [139/200], loss: 0.02480851300060749\n",
      "epoch [140/200], loss: 0.022769685834646225\n",
      "epoch [141/200], loss: 0.023592855781316757\n",
      "epoch [142/200], loss: 0.022849151864647865\n",
      "epoch [143/200], loss: 0.02382149174809456\n",
      "epoch [144/200], loss: 0.025545377284288406\n",
      "epoch [145/200], loss: 0.024413904175162315\n",
      "epoch [146/200], loss: 0.022984271869063377\n",
      "epoch [147/200], loss: 0.020312227308750153\n",
      "epoch [148/200], loss: 0.022764714434742928\n",
      "epoch [149/200], loss: 0.02410542406141758\n",
      "epoch [150/200], loss: 0.021196944639086723\n",
      "epoch [151/200], loss: 0.024944428354501724\n",
      "epoch [152/200], loss: 0.020316550508141518\n",
      "epoch [153/200], loss: 0.021176178008317947\n",
      "epoch [154/200], loss: 0.024150704964995384\n",
      "epoch [155/200], loss: 0.0246724933385849\n",
      "epoch [156/200], loss: 0.02498955838382244\n",
      "epoch [157/200], loss: 0.02381267584860325\n",
      "epoch [158/200], loss: 0.02068127691745758\n",
      "epoch [159/200], loss: 0.023187028244137764\n",
      "epoch [160/200], loss: 0.024184221401810646\n",
      "epoch [161/200], loss: 0.023077450692653656\n",
      "epoch [162/200], loss: 0.02263808622956276\n",
      "epoch [163/200], loss: 0.022141551598906517\n",
      "epoch [164/200], loss: 0.024347057566046715\n",
      "epoch [165/200], loss: 0.022833531722426414\n",
      "epoch [166/200], loss: 0.022945033386349678\n",
      "epoch [167/200], loss: 0.02506396919488907\n",
      "epoch [168/200], loss: 0.022155215963721275\n",
      "epoch [169/200], loss: 0.021521147340536118\n",
      "epoch [170/200], loss: 0.021104319021105766\n",
      "epoch [171/200], loss: 0.02586088515818119\n",
      "epoch [172/200], loss: 0.021816162392497063\n",
      "epoch [173/200], loss: 0.021823043003678322\n",
      "epoch [174/200], loss: 0.024076052010059357\n",
      "epoch [175/200], loss: 0.022169671952724457\n",
      "epoch [176/200], loss: 0.021222151815891266\n",
      "epoch [177/200], loss: 0.023724745959043503\n",
      "epoch [178/200], loss: 0.023799186572432518\n",
      "epoch [179/200], loss: 0.025604253634810448\n",
      "epoch [180/200], loss: 0.023243609815835953\n",
      "epoch [181/200], loss: 0.022859513759613037\n",
      "epoch [182/200], loss: 0.023199796676635742\n",
      "epoch [183/200], loss: 0.02134982869029045\n",
      "epoch [184/200], loss: 0.02383289486169815\n",
      "epoch [185/200], loss: 0.026267515495419502\n",
      "epoch [186/200], loss: 0.02305474691092968\n",
      "epoch [187/200], loss: 0.023550651967525482\n",
      "epoch [188/200], loss: 0.022621244192123413\n",
      "epoch [189/200], loss: 0.025789029896259308\n",
      "epoch [190/200], loss: 0.0238809734582901\n",
      "epoch [191/200], loss: 0.025469254702329636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [192/200], loss: 0.023518387228250504\n",
      "epoch [193/200], loss: 0.02358437143266201\n",
      "epoch [194/200], loss: 0.022740941494703293\n",
      "epoch [195/200], loss: 0.02223658189177513\n",
      "epoch [196/200], loss: 0.024499384686350822\n",
      "epoch [197/200], loss: 0.0260175671428442\n",
      "epoch [198/200], loss: 0.022897666320204735\n",
      "epoch [199/200], loss: 0.022216806188225746\n",
      "epoch [200/200], loss: 0.023668775334954262\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "def plot_sample_img(img, name):\n",
    "    img = img.view(1, 28, 28)\n",
    "    save_image(img, './sample_{}.png'.format(name))\n",
    "\n",
    "\n",
    "def min_max_normalization(tensor, min_value, max_value):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor / max_tensor\n",
    "    tensor = tensor * (max_value - min_value) + min_value\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def tensor_round(tensor):\n",
    "    return torch.round(tensor)\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda tensor:min_max_normalization(tensor, 0, 1)),\n",
    "    transforms.Lambda(lambda tensor:tensor_round(tensor))\n",
    "])\n",
    "\n",
    "dataset = MNIST('./data', transform=img_transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 28 * 28),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = autoencoder() # .cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img) #.cuda()\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "        MSE_loss = nn.MSELoss()(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print(f'epoch [{epoch+1}/{num_epochs}], loss: {loss}')\n",
    "    #print(f'epoch [{epoch+1}/{num_epochs}], loss:{loss.data[0]}, MSE_loss:{MSE_loss.data[0]}')\n",
    "    if epoch % 10 == 0:\n",
    "        x = to_img(img.cpu().data)\n",
    "        x_hat = to_img(output.cpu().data)\n",
    "        save_image(x, './mlp_img/x_{}.png'.format(epoch))\n",
    "        save_image(x_hat, './mlp_img/x_hat_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './sim_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorcho",
   "language": "python",
   "name": "pytorcho"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
