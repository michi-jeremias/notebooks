{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../data/covtype'):\n",
    "    os.makedirs('../data/covtype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................................] 11240707 / 11240707"
     ]
    }
   ],
   "source": [
    "filename = wget.download(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(filename, 'rb') as f_in:\n",
    "    with open('../data/covtype/covtype.csv', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/covtype/covtype.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581011"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_total = len(df)\n",
    "n_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_indices, test_indices = train_test_split(range(n_total), test_size=0.2, random_state=0)\n",
    "train_indices, val_indices = train_test_split(train_val_indices, test_size=0.2/0.6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = df.iloc[train_indices]\n",
    "valdf = df.iloc[val_indices]\n",
    "testdf = df.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = traindf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.to_csv('../data/covtype/train_covertype.csv', index=False, header=False)\n",
    "valdf.to_csv('../data/covtype/val_covertype.csv', index=False, header=False)\n",
    "testdf.to_csv('../data/covtype/test_covertype.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from functools import partial\n",
    "from torch.utils.data import TensorDataset\n",
    "from dltools.callback import AvgStatsCallback, sched_lin, sched_cos, Recorder, AvgStatsCallback\n",
    "from dltools.callback import ParamScheduler, combine_scheds, Callback, LearningrateFinder, DeviceCallback\n",
    "from dltools.callback import BatchTransformXCallback\n",
    "from dltools.databunch import DataBunch\n",
    "from dltools.functions import create_learner, get_dls, get_model, get_model_func, listify, normalize_to, get_data\n",
    "from dltools.functions import view_tfm, init_cnn, activation_stats\n",
    "from dltools.hook import Hook, Hooks, ListContainer, children, append_stats, append_stats_hist, get_min, get_hist\n",
    "from dltools.layer import Lambda, flatten, conv_layer, GeneralRelu\n",
    "from dltools.metrics import accuracy\n",
    "from dltools.runner import get_learn_run, get_cnn_model, get_cnn_layers, init_cnn, get_runner\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !type fastaimanual.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes rounding apparently\n",
    "torch.set_num_threads(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_data()\n",
    "x_train, x_valid = normalize_to(x_train, x_valid)\n",
    "train_ds, valid_ds = TensorDataset(x_train, y_train), TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.mean(), x_train.std(), x_valid.mean(), x_valid.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh, bs = 50, 512\n",
    "c = y_train.max().item()+1\n",
    "loss_func = F.cross_entropy\n",
    "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of filters\n",
    "nfs = [8, 16, 32, 64, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_view = view_tfm(1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbfs = [LearningrateFinder, Recorder]\n",
    "cbfs = [DeviceCallback, Recorder, partial(AvgStatsCallback, accuracy), partial(BatchTransformXCallback, mnist_view)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Hooks Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hooks = [Hook(l, append_stats) for l in children(model[:4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for h in hooks:\n",
    "    plt.plot(h.stats[0])\n",
    "    h.remove()\n",
    "plt.legend(range(4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sched = combine_scheds([0.5, 0.5], [sched_cos(0.2, 1.), sched_cos(1., 0.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn, run = get_learn_run(nfs, data, 1., conv_layer, cbs=cbfs+[partial(ParamScheduler, 'lr', sched)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# In the notebook the line is ... for l in children(model[:4]) because the model\n",
    "# resides in the __main__ namespace, and therefore the hooks can be registered in the model there.\n",
    "# However, since get_learn_run() is in dltools.runner, the model resides in dltools.runner, in the Learner\n",
    "# object learn, and can only be accessed via learn.\n",
    "# hooks = [Hook(l, append_stats) for l in children(model[:4])] # fastai notebook\n",
    "hooks = [Hook(l, append_stats) for l in children(learn.model[:4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for h in hooks:\n",
    "    plt.plot(h.stats[0])\n",
    "plt.legend(range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for h in hooks:\n",
    "    print(h.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 1., conv_layer, uniform=True,\n",
    "                          cbs=cbfs+[partial(ParamScheduler,'lr', sched)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run.fit(8, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with Hooks(model, append_stats) as hooks:\n",
    "    run.fit(1, learn)\n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    for h in hooks:\n",
    "        ms,ss = h.stats\n",
    "        ax0.plot(ms[:10])\n",
    "        ax1.plot(ss[:10])        \n",
    "    plt.legend(range(5));\n",
    "    \n",
    "    fig,(ax0,ax1) = plt.subplots(1,2, figsize=(10,4))\n",
    "    for h in hooks:\n",
    "        ms,ss = h.stats\n",
    "        ax0.plot(ms)\n",
    "        ax1.plot(ss)\n",
    "    plt.legend(range(5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run.fit(8, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with Hooks(model, append_stats) as hooks:\n",
    "    run.fit(1, learn)\n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    for h in hooks:\n",
    "        ms, ss = h.stats\n",
    "        ax0.plot(ms[:10])\n",
    "        ax1.plot(ss[:10])\n",
    "    plt.legend(range(6))\n",
    "    \n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    for h in hooks:\n",
    "        ms, ss = h.stats\n",
    "        ax0.plot(ms)\n",
    "        ax1.plot(ss)\n",
    "    plt.legend(range(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Initialization and telemetry setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Check initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_layers_simple(data, nfs):\n",
    "    nfs = [1] + nfs\n",
    "    return [\n",
    "        conv2d(nfs[i], nfs[i+1], 5 if i==0 else 3)\n",
    "        for i in range(len(nfs)-1)\n",
    "    ] + [nn.AdaptiveAvgPool2d(1), Lambda(flatten), nn.Linear(nfs[-1], data.c)]\n",
    "\n",
    "def get_cnn_model_simple(data, nfs): return nn.Sequential(*get_cnn_layers_simple(data, nfs))\n",
    "\n",
    "def conv2d(ni, nf, ks=3, stride=2):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride), nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = get_cnn_model_simple(data, nfs)\n",
    "learn, run = get_runner(model, data, lr=0.9, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mnist_resize(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = mnist_resize(x).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mean and std around 0, 1 from the normalization\n",
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# after the first layer, the mean and std are not close to 0 and 1 anymore\n",
    "p = model.cuda()[0](x)\n",
    "p.mean(), p.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initialize the model parameters with kaiming\n",
    "for l in model.cuda():\n",
    "    if isinstance(l, nn.Sequential):\n",
    "        init.kaiming_normal_(l[0].weight)\n",
    "        l[0].bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# std is now close to 1, and mean is close to 0.5 due to relu cutoff\n",
    "p = model.cuda()[0](x)\n",
    "p.mean(), p.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Can also use get_cnn_model (with the conv_layer argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_cnn_model(data, nfs, conv_layer)\n",
    "learn, run = get_runner(model, data, lr=0.9, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mnist_resize(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = mnist_resize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mean and std around 0, 1 from the normalization\n",
    "x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# after the first layer, the mean and std are not close to 0 and 1 anymore\n",
    "p = model[0](x)\n",
    "p.mean(), p.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initialize the model parameters with kaiming\n",
    "for l in model:\n",
    "    if isinstance(l, nn.Sequential):\n",
    "        init.kaiming_normal_(l[0].weight)\n",
    "        l[0].bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# std is now close to 1, and mean is close to 0.5 due to relu cutoff\n",
    "p = model[0](x)\n",
    "p.mean(), p.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p1 = model[1](model[0](x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p1.mean(), p1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.train_dl.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def conv2d(ni, nf, ks=3, stride=2):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride), nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_hist(h):\n",
    "    return torch.stack(h.stats[2]).t().float().log1p()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_min(h):\n",
    "    # Assume first two bins of the histogram contain values close to 0.\n",
    "    # Show relative amount of data in these bins compared to all bins.\n",
    "    # This gives a ratio of values close to 0.\n",
    "    h1 = torch.stack(h.stats[2]).t().float()\n",
    "    return h1[:2].sum(0)/h1.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = get_cnn_model_simple(data, nfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn, run = get_runner(model, data, lr=0.9, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l in model:\n",
    "    if isinstance(l, nn.Sequential):\n",
    "        init.kaiming_normal_(l[0].weight)\n",
    "        l[0].bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# init_cnn(model, uniform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with Hooks(model, append_stats_hist) as hooks:\n",
    "    run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,2, figsize=(15,6))\n",
    "for ax,h in zip(axes.flatten(), hooks[:4]):\n",
    "    ax.imshow(get_hist(h), origin='lower')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,2, figsize=(15,6))\n",
    "for ax,h in zip(axes.flatten(), hooks[:4]):\n",
    "    ax.plot([0, 110], [1., 1.], c='r', linewidth=1)\n",
    "    ax.plot(get_min(h))\n",
    "    ax.set_ylim(0,1.1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with Hooks(model, append_stats_hist) as hooks:\n",
    "    telemetrize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Telemetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Telemetry start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltools.hook import telemetrize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_cnn_model(data, nfs, conv_layer)\n",
    "learn, run = get_runner(model, data, lr=0.9, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_cnn(model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activation_stats(model, data, [-1, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.train_ds.tensors[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(learn.data.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Hooks(model, append_stats_hist) as hooks:\n",
    "    run.fit(1, learn)\n",
    "    telemetrize(hooks, xlim=1*len(learn.data.train_ds)//bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Telemetry for model with generalized relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltools.runner import get_cnn_grelu_model\n",
    "from dltools.hook import telemetrize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak = [0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "clamp = [0.4, 0.2, 0.4, 0.2, 0.2]\n",
    "model = get_cnn_grelu_model(data, nfs, leak, clamp, conv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, run = get_runner(model, data, lr=0.5, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_cnn(model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_stats(model, data, [-1, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Hooks(model, append_stats_hist) as hooks:\n",
    "    run.fit(2, learn)\n",
    "    telemetrize(hooks, 2*len(learn.data.train_ds)//bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  get_cnn_model(data, nfs, conv_layer, leak=0.1, sub=0.4, maxv=6.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_stats(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_cnn(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_stats(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_runner(model, data, lr=0.9, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Hooks(model, append_stats_hist) as hooks:\n",
    "    run.fit(1, learn)\n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    for h in hooks:\n",
    "        ms, ss, hi = h.stats\n",
    "        ax0.plot(ms[:10])\n",
    "        ax1.plot(ss[:10])\n",
    "        h.remove()\n",
    "    plt.legend(range(5));\n",
    "    \n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    for h in hooks:\n",
    "        ms, ss, hi = h.stats\n",
    "        ax0.plot(ms)\n",
    "        ax1.plot(ss)\n",
    "    plt.legend(range(5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = combine_scheds([0.5, 0.5], [sched_cos(0.2, 1.), sched_cos(1., 0.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, run = get_learn_run(nfs, data, lr=1., layer=conv_layer, cbs=cbfs + [partial(ParamScheduler, 'lr', sched)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fit(8, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36-fastai",
   "language": "python",
   "name": "p36-fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
