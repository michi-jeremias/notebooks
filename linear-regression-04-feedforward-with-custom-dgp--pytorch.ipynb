{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Linear Regression with custom data generatig process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy, PyTorch, torch.nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will predict crop yields for 2 different fruits: apples, oranges. The predictions are based on the input variables temperature, rainfall, humidity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data generating process is as follows:\n",
    "* apples = 0.5\\*temperature + 0.5\\*rainfall + 0.2\\*humidity\n",
    "* oranges = 1\\*temperature + 0.2\\*rainfall - 0.1\\*humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randint??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4845, 0.1702, 0.7258, 0.8678])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[31., 54.,  4.],\n",
      "        [58., 15., 60.],\n",
      "        [30., 69., 76.],\n",
      "        [40., 34., 86.],\n",
      "        [47., 74., 43.]])\n"
     ]
    }
   ],
   "source": [
    "# Define input variables\n",
    "temperature = torch.randint(low=20, high=70, size=(100,), requires_grad=False)\n",
    "rainfall = torch.randint(low=0, high=100, size=(100,), requires_grad=False)\n",
    "humidity = torch.randint(low=0, high=100, size=(100,), requires_grad=False)\n",
    "inputs = torch.stack([temperature, rainfall, humidity], 1).type(torch.float32)\n",
    "print(inputs[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([43.3000, 48.5000, 64.7000, 54.2000, 69.1000])\n",
      "tensor([41.4000, 55.0000, 36.2000, 38.2000, 57.5000])\n",
      "tensor([[43.3000, 41.4000],\n",
      "        [48.5000, 55.0000],\n",
      "        [64.7000, 36.2000],\n",
      "        [54.2000, 38.2000],\n",
      "        [69.1000, 57.5000]])\n"
     ]
    }
   ],
   "source": [
    "# Calculate target variables based on DGP\n",
    "apples_coeff = torch.tensor([0.5, 0.5, 0.2])\n",
    "apples = torch.sum(inputs*apples_coeff, dim=1)\n",
    "print(apples[:5])\n",
    "oranges_coeff = torch.tensor([1, 0.2, -0.1])\n",
    "oranges = torch.sum(inputs*oranges_coeff, dim=1)\n",
    "print(oranges[:5])\n",
    "targets = torch.stack([apples, oranges], dim=1).type(torch.float32)\n",
    "print(targets[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset, Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a dataset and a dataloader, which allow us to split the data into batches while training. It also lets us shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorDataset, DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[31., 54.,  4.],\n",
       "         [58., 15., 60.],\n",
       "         [30., 69., 76.]]), tensor([[43.3000, 41.4000],\n",
       "         [48.5000, 55.0000],\n",
       "         [64.7000, 36.2000]]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(3, 5)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(5, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        #x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = SimpleNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "lr = 1e-5\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_fn(model(inputs), targets)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the same function fit as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "def fit(num_epochs, model, loss_fn, opt):    \n",
    "    for epoch in range(num_epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            # Forward            \n",
    "            preds = model(xb)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            # Gradient descent\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        if epoch%10==0:\n",
    "            print('Training loss:', loss_fn(model(inputs), targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training error should converge quickly to the minimum since we have a perfect linear relationship in the DGP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Training loss: tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Training loss: tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Training loss: tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Training loss: tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Training loss: tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Training loss: tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Training loss: tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Training loss: tensor(0.0150, grad_fn=<MseLossBackward>)\n",
      "Training loss: tensor(0.0151, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Train for 100 epochs\n",
    "#losses = []\n",
    "fit(num_epochs=100, model=model, loss_fn=loss_fn, opt=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the model and optimizer for re-training from zero.\n",
    "model = SimpleNet()\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b146a39f60>]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[43.5506, 41.5015],\n",
      "        [48.4779, 54.9917],\n",
      "        [64.7563, 36.2240],\n",
      "        [54.2249, 38.2111],\n",
      "        [69.0825, 57.4938],\n",
      "        [76.3744, 37.0912],\n",
      "        [72.7191, 36.0092],\n",
      "        [37.3405, 25.3977],\n",
      "        [39.6335, 36.2545],\n",
      "        [48.4628, 53.1857]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "print(preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[43.3000, 41.4000],\n",
      "        [48.5000, 55.0000],\n",
      "        [64.7000, 36.2000],\n",
      "        [54.2000, 38.2000],\n",
      "        [69.1000, 57.5000],\n",
      "        [76.4000, 37.1000],\n",
      "        [72.7000, 36.0000],\n",
      "        [37.1000, 25.3000],\n",
      "        [39.5000, 36.2000],\n",
      "        [48.5000, 53.2000]])\n"
     ]
    }
   ],
   "source": [
    "print(targets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 fastai 1.0 Cuda 10.0",
   "language": "python",
   "name": "p36-fastai10-cuda100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
