{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn configuration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset class for tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader#, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, data, cat_cols=None, output_col=None):\n",
    "        \"\"\"\n",
    "        Characterizes a Dataset for PyTorch\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        data: pandas data frame\n",
    "          The data frame object for the input data. It must\n",
    "          contain all the continuous, categorical and the\n",
    "          output columns to be used.\n",
    "\n",
    "        cat_cols: List of strings\n",
    "          The names of the categorical columns in the data.\n",
    "          These columns will be passed through the embedding\n",
    "          layers in the model. These columns must be\n",
    "          label encoded beforehand. \n",
    "\n",
    "        output_col: string\n",
    "          The name of the output variable column in the data\n",
    "          provided.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.n, self.c = data.shape\n",
    "        print(data.shape)\n",
    "        \n",
    "        if output_col:\n",
    "            self.y = data[output_col]\n",
    "        else:\n",
    "            self.y = np.zeros(self.n, 1)\n",
    "        \n",
    "        self.cat_cols = cat_cols if cat_cols else []\n",
    "        self.cont_cols = [col for col in data.columns if col not in self.cat_cols + [output_col]]\n",
    "        \n",
    "        if self.cont_cols:\n",
    "            self.cont_X = data[self.cont_cols].astype(np.float32).values\n",
    "        else:\n",
    "            self.cont_X = np.zeros((self.n, 1))\n",
    "        \n",
    "        if self.cat_cols:\n",
    "            self.cat_X = data[cat_cols].astype(np.int64).values\n",
    "        else:\n",
    "            self.cat_X = np.zeros((self.n, 1))\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns total number of samples.\n",
    "        \"\"\"\n",
    "        return self.n\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one sample of data.\n",
    "        \"\"\"\n",
    "        return [self.y[idx], self.cont_X[idx], self.cat_X[idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, emb_dims, no_of_cont, lin_layer_sizes, output_size, emb_dropout, lin_layer_dropouts, verb=False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        emb_dims: List of two element tuples\n",
    "          This list will contain a two element tuple for each\n",
    "          categorical feature. The first element of a tuple will\n",
    "          denote the number of unique values of the categorical\n",
    "          feature. The second element will denote the embedding\n",
    "          dimension to be used for that feature.\n",
    "\n",
    "        no_of_cont: Integer\n",
    "          The number of continuous features in the data.\n",
    "\n",
    "        lin_layer_sizes: List of integers.\n",
    "          The size of each linear layer. The length will be equal\n",
    "          to the total number\n",
    "          of linear layers in the network.\n",
    "\n",
    "        output_size: Integer\n",
    "          The size of the final output.\n",
    "\n",
    "        emb_dropout: Float\n",
    "          The dropout to be used after the embedding layers.\n",
    "\n",
    "        lin_layer_dropouts: List of floats\n",
    "          The dropouts to be used after each linear layer.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding layers\n",
    "        self.emb_layers = nn.ModuleList([nn.Embedding(x, y) for x, y in emb_dims])\n",
    "        \n",
    "        no_of_embs = sum([y for x, y in emb_dims])\n",
    "        self.no_of_embs = no_of_embs\n",
    "        self.no_of_cont = no_of_cont\n",
    "        \n",
    "        if verb:\n",
    "            print(self.emb_layers)\n",
    "            print(f'Total number of embeddings: {self.no_of_embs}')\n",
    "            print(f'Total number of cont. vars: {self.no_of_cont}')\n",
    "\n",
    "        # Linear layers\n",
    "        # First layer num of rows = total sum of embeddings (over all cat vars) + sum of cont vars\n",
    "        first_lin_layer = nn.Linear(in_features=self.no_of_embs + self.no_of_cont, out_features=lin_layer_sizes[0])\n",
    "\n",
    "        # All linear layers\n",
    "        #other_lin_layers = nn.ModuleList[nn.Linear(lin_layer_sizes[i], lin_layer_sizes[i+1]) for i in range(len(lin_layer_sizes) - 1)]\n",
    "        #self.lin_layers = nn.ModuleList([first_lin_layer] + [other_lin_layers])\n",
    "\n",
    "        self.lin_layers = nn.ModuleList([first_lin_layer] +\n",
    "                                        [nn.Linear(lin_layer_sizes[i], lin_layer_sizes[i+1])\n",
    "                                         for i in range(len(lin_layer_sizes) - 1)])\n",
    "\n",
    "        # Initialze parameters\n",
    "        for lin_layer in self.lin_layers:\n",
    "            nn.init.kaiming_normal_(lin_layer.weight.data)\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(in_features=lin_layer_sizes[-1], out_features=output_size)\n",
    "\n",
    "        # Batch norm layers\n",
    "        self.first_bn_layer = nn.BatchNorm1d(self.no_of_cont)\n",
    "        self.bn_layers = nn.ModuleList([nn.BatchNorm1d(size) for size in lin_layer_sizes])\n",
    "\n",
    "        # Dropout layers\n",
    "        self.emb_dropout_layer = nn.Dropout(emb_dropout)\n",
    "        self.dropout_layers = nn.ModuleList([nn.Dropout(size) for size in lin_layer_dropouts])\n",
    "        \n",
    "    def forward(self, cont_data, cat_data):\n",
    "        if self.no_of_embs != 0:\n",
    "            x = [emb_layer(cat_data[:, i]) for i, emb_layer in enumerate(self.emb_layers)]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_dropout_layer(x)\n",
    "        \n",
    "        if self.no_of_cont != 0:\n",
    "            normalized_cont_data = self.first_bn_layer(cont_data)\n",
    "            \n",
    "            if self.no_of_embs != 0:\n",
    "                x = torch.cat([x, normalized_cont_data], 1)\n",
    "            else:\n",
    "                x = normalized_cont_data\n",
    "        \n",
    "        for lin_layer, dropout_layer, bn_layer in zip(self.lin_layers, self.dropout_layers, self.bn_layers):\n",
    "            x = F.relu(lin_layer(x))\n",
    "            x = bn_layer(x)\n",
    "            x = dropout_layer(x)\n",
    "        \n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_layer_sizes = [50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_cont = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'no_of_embs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b3c44748b4c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfirst_lin_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_of_embs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mno_of_cont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlin_layer_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'no_of_embs' is not defined"
     ]
    }
   ],
   "source": [
    "first_lin_layer = nn.Linear(in_features=no_of_embs + no_of_cont, out_features=lin_layer_sizes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb_dims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ab5a0a095035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memb_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memb_dims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0memb_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emb_dims' is not defined"
     ]
    }
   ],
   "source": [
    "emb_layers = nn.ModuleList([nn.Embedding(x, y) for x, y in emb_dims])\n",
    "emb_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb_dims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-96209bf2434e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mno_of_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memb_dims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mno_of_embs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emb_dims' is not defined"
     ]
    }
   ],
   "source": [
    "no_of_embs = sum([y for x, y in emb_dims])\n",
    "no_of_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb_dims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-51c6fe1c7115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memb_dims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'emb_dims' is not defined"
     ]
    }
   ],
   "source": [
    "sum([y for x, y in emb_dims])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import and pre-process data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_description.txt  sample_submission.csv  train.csv\r\n",
      "models\t\t      test.csv\t\t     train_tiny.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/houseprice/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = Path('../data/houseprice/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: implement fillmissing, auto-generate one-hot vector for NAs, mapping from train to val/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: implement normalization, mapping from train to val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'train.csv', sep=',', usecols=['SalePrice', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', \n",
    "                                                           'Street', 'YearBuilt', 'LotShape', '1stFlrSF',\n",
    "                                                           '2ndFlrSF']).dropna().reset_index(drop=True)\n",
    "df_test = pd.read_csv(path/'test.csv', sep=',', usecols=['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', \n",
    "                                                           'Street', 'YearBuilt', 'LotShape', '1stFlrSF',\n",
    "                                                           '2ndFlrSF']).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor_train = torch.tensor(df_train.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>2003</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2001</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1915</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  YearBuilt  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg       2003   \n",
       "1          20       RL         80.0     9600   Pave      Reg       1976   \n",
       "2          60       RL         68.0    11250   Pave      IR1       2001   \n",
       "3          70       RL         60.0     9550   Pave      IR1       1915   \n",
       "4          60       RL         84.0    14260   Pave      IR1       2000   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  SalePrice  \n",
       "0       856       854     208500  \n",
       "1      1262         0     181500  \n",
       "2       920       866     223500  \n",
       "3       961       756     140000  \n",
       "4      1145      1053     250000  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_train.drop('Id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 10)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,c = df_train.shape\n",
    "n, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['MSSubClass', 'MSZoning', 'Street', 'LotShape', 'YearBuilt']\n",
    "output_feature = 'SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for cat_col in categorical_features:\n",
    "    label_encoders[cat_col] = LabelEncoder()\n",
    "    df_train[cat_col] = label_encoders[cat_col].fit_transform(df_train[cat_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  YearBuilt  \\\n",
       "0           5         3         65.0     8450       1         3        104   \n",
       "1           0         3         80.0     9600       1         3         77   \n",
       "2           5         3         68.0    11250       1         0        102   \n",
       "3           6         3         60.0     9550       1         0         19   \n",
       "4           5         3         84.0    14260       1         0        101   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  SalePrice  \n",
       "0       856       854     208500  \n",
       "1      1262         0     181500  \n",
       "2       920       866     223500  \n",
       "3       961       756     140000  \n",
       "4      1145      1053     250000  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass          5.0\n",
       "MSZoning            3.0\n",
       "LotFrontage        65.0\n",
       "LotArea          8450.0\n",
       "Street              1.0\n",
       "LotShape            3.0\n",
       "YearBuilt         104.0\n",
       "1stFlrSF          856.0\n",
       "2ndFlrSF          854.0\n",
       "SalePrice      208500.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['MSSubClass', 'MSZoning', 'Street', 'LotShape', 'YearBuilt'], 'SalePrice')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features, output_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15, 8), (5, 3), (2, 1), (4, 2), (112, 50)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims = [int(df_train[col].nunique()) for col in categorical_features]\n",
    "emb_dims = [(card, min(50, (card+1)//2)) for card in cat_dims]\n",
    "emb_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_layer_sizes = [50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1201, 10)\n"
     ]
    }
   ],
   "source": [
    "dataset = TabularDataset(data=df_train, cat_cols=categorical_features, output_col=output_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_epochs = 5\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = FeedForwardNN(emb_dims, no_of_cont=4, lin_layer_sizes=lin_layer_sizes, output_size=1, emb_dropout=0.04,\n",
    "                      lin_layer_dropouts=[0.001, 0.01]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/envs/p36-fastai10-cuda100/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "/home/michael/anaconda3/envs/p36-fastai10-cuda100/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/michael/anaconda3/envs/p36-fastai10-cuda100/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6824e+10, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(4.1629e+10, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(3.2225e+10, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(4.0106e+10, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(4.2226e+10, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(no_of_epochs):\n",
    "    for y, cont_x, cat_x in dataloader:\n",
    "        #cat_x = cat_x.to(device)\n",
    "        cat_x = torch.tensor(cat_x, dtype=torch.long, device=device)         # long is needed for embeddings\n",
    "        #cont_x = cont_x.to(device)\n",
    "        cont_x = torch.tensor(cont_x, dtype=torch.float32, device=device)\n",
    "        #y = y.to(device)\n",
    "        y = torch.tensor(y, dtype=torch.float32, device=device)\n",
    "        \n",
    "        # Forward\n",
    "        preds = model(cont_x, cat_x)                                         # this calls model.forward()\n",
    "        loss = criterion(preds, y)\n",
    "                \n",
    "        # Backward pass and zero grad\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4178],\n",
       "        [-0.2862],\n",
       "        [-0.1400],\n",
       "        [ 0.2611],\n",
       "        [-0.2501],\n",
       "        [ 0.3144],\n",
       "        [-0.0731],\n",
       "        [-0.6758],\n",
       "        [ 0.4927],\n",
       "        [-0.5883],\n",
       "        [-0.0403],\n",
       "        [-0.1237],\n",
       "        [-0.2576],\n",
       "        [-0.9774],\n",
       "        [ 0.1409],\n",
       "        [-0.5651],\n",
       "        [-0.3184],\n",
       "        [-0.2968],\n",
       "        [-0.6893],\n",
       "        [ 0.7589],\n",
       "        [ 0.4632],\n",
       "        [-0.1995],\n",
       "        [ 0.4237],\n",
       "        [-0.2993],\n",
       "        [-0.2863],\n",
       "        [-0.6764],\n",
       "        [ 0.2694],\n",
       "        [-0.8707],\n",
       "        [ 0.6386],\n",
       "        [-0.4427],\n",
       "        [ 0.3593],\n",
       "        [ 1.0640],\n",
       "        [-0.2333],\n",
       "        [ 0.5831],\n",
       "        [ 0.4855],\n",
       "        [ 0.1318],\n",
       "        [-0.3230],\n",
       "        [-0.2893],\n",
       "        [-0.7587],\n",
       "        [-0.0176],\n",
       "        [-0.5532],\n",
       "        [ 0.1848],\n",
       "        [-0.4049],\n",
       "        [-0.0855],\n",
       "        [-0.1403],\n",
       "        [-0.4251],\n",
       "        [ 0.1677],\n",
       "        [-0.0505],\n",
       "        [ 0.7031]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 fastai 1.0 Cuda 10.0",
   "language": "python",
   "name": "p36-fastai10-cuda100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
